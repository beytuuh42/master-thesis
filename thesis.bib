@book{mohri2018foundations,
	title        = {Foundations of machine learning},
	author       = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	year         = 2018
}

@inproceedings{alzubi2018machine,
	  title={Machine learning from theory to algorithms: an overview},
	  author={Alzubi, Jafar and Nayyar, Anand and Kumar, Akshi},
	  booktitle={Journal of physics: conference series},
	  volume={1142},
	  number={1},
	  pages={012012},
	  year={2018},
	  organization={IOP Publishing}
}

@book{richardsutton2018,
	title        = {Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning series)},
	author       = {Richard S. Sutton},
	year         = 2018,
	month        = nov,
	publisher    = {A Bradford Book},
	isbn         = {0262039249},
	url          = {https://www.xarg.org/ref/a/0262039249/},
	description  = {Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning series) (Book, 2018)},
	interhash    = {43d72b9b2e4d2658016e5c6320c6b425},
	intrahash    = {7d6a7ff98dd4f1d4be00a0548da93a4a}
}

@misc{silver2020MDP,
	title        = {{Lecture 2: Markov Decision Processes}},
	author       = {Silver, David},
	year         = 2020,
	month        = mar,
	note         = {(Accessed on 11/14/2022)},
	url = {https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf}
}

@misc{silver2020DQN,
	title        = {{Lecture 6: Value Function Approximation}},
	author       = {Silver, David},
	year         = 2020,
	month        = mar,
	note         = {(Accessed on 11/14/2022)},
	url = {https://www.davidsilver.uk/wp-content/uploads/2020/03/FA.pdf}
}

@misc{silver2020Policy,
	title        = {{Lecture 7: Policy Gradient Methods}},
	author       = {Silver, David},
	year         = 2020,
	month        = mar,
	note         = {(Accessed on 11/15/2022)},
	url = {https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf}
}

@article{Arulkumaran_2017,
	doi = {10.1109/msp.2017.2743240},
	url = {https://doi.org/10.1109%2Fmsp.2017.2743240},
	year = 2017,
	month = {nov},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {34},
	number = {6},
	pages = {26--38},
	author = {Kai Arulkumaran and Marc Peter Deisenroth and Miles Brundage and Anil Anthony Bharath},
	title = {Deep Reinforcement Learning: A Brief Survey},
	journal = {{IEEE} Signal Processing Magazine}
}

@inproceedings{9418283,
	author = {Akanksha, Eisha and Sehgal, Jyoti and Sharma, Neeraj and Gulati, Kamal},
	year = {2021},
	month = {04},
	pages = {1416-1423},
	title = {Review on Reinforcement Learning, Research Evolution and Scope of Application},
	doi = {10.1109/ICCMC51019.2021.9418283}
}

@article{2013arXiv1312.5602M,
	title        = {{Playing Atari with Deep Reinforcement Learning}},
	author       = {{Mnih}, Volodymyr and {Kavukcuoglu}, Koray and {Silver}, David and {Graves}, Alex and {Antonoglou}, Ioannis and {Wierstra}, Daan and {Riedmiller}, Martin},
	year         = 2013,
	month        = dec,
	journal      = {arXiv e-prints},
	pages        = {arXiv:1312.5602},
	keywords     = {Computer Science - Machine Learning},
	eid          = {arXiv:1312.5602},
	archiveprefix = {arXiv},
	eprint       = {1312.5602},
	primaryclass = {cs.LG},
	adsurl       = {https://ui.adsabs.harvard.edu/abs/2013arXiv1312.5602M},
	adsnote      = {Provided by the SAO/NASA Astrophysics Data System}
}


@inproceedings{behzadan2017vulnerability,
	  title={Vulnerability of deep reinforcement learning to policy induction attacks},
	  author={Behzadan, Vahid and Munir, Arslan},
	  booktitle={International Conference on Machine Learning and Data Mining in Pattern Recognition},
	  pages={262--275},
	  year={2017},
	  organization={Springer}
}

@article{Spears2017ScaleInvariant,
	author = {Spears, Tyler and Jacques, Brandon and Howard, Marc and Sederberg, Per},
	year = {2017},
	month = {12},
	pages = {},
	title = {Scale-invariant temporal history (SITH): optimal slicing of the past in an uncertain world}
}

@article{mnih2015human,
	  title={Human-level control through deep reinforcement learning},
	  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	  journal={nature},
	  volume={518},
	  number={7540},
	  pages={529--533},
	  year={2015},
	  publisher={Nature Publishing Group}
}

@inproceedings{van2016deep,
	  title={Deep reinforcement learning with double q-learning},
	  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
	  booktitle={Proceedings of the AAAI conference on artificial intelligence},
	  volume={30},
	  number={1},
	  year={2016}
}

@article{schulman2017proximal,
	  title={Proximal policy optimization algorithms},
	  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	  journal={arXiv preprint arXiv:1707.06347},
	  year={2017}
}

@inproceedings{schulman2015trust,
	  title={Trust region policy optimization},
	  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	  booktitle={International conference on machine learning},
	  pages={1889--1897},
	  year={2015},
	  organization={PMLR}
}

@article{williams1992simple,
	  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	  author={Williams, Ronald J},
	  journal={Machine learning},
	  volume={8},
	  number={3},
	  pages={229--256},
	  year={1992},
	  publisher={Springer}
}

@misc{Howtopla33:online,
	author = {},
	title = {How to play Mastermind | Official Rules | UltraBoardGames},
	howpublished = {\url{https://www.ultraboardgames.com/mastermind/game-rules.php}},
	month = {},
	year = {},
	note = {(Accessed on 11/21/2022)}
}

  @misc{enwiki:1122862799,
	    author = "{Wikipedia contributors}",
	    title = "Mastermind (board game) --- {Wikipedia}{,} The Free Encyclopedia",
	    year = "2022",
	    url = "https://en.wikipedia.org/w/index.php?title=Mastermind_(board_game)&oldid=1122862799",
	    note = "[Online; accessed 21-November-2022]"
  }

  @misc{ enwiki:1120935103,
	    author = "{Wikipedia contributors}",
	    title = "Battleship (game) --- {Wikipedia}{,} The Free Encyclopedia",
	    year = "2022",
	    url = "https://en.wikipedia.org/w/index.php?title=Battleship_(game)&oldid=1120935103",
	    note = "[Online; accessed 21-November-2022]"
  }

@misc{TFAgents,
	  title = {{TF-Agents}: A library for Reinforcement Learning in TensorFlow},
	  author = {Sergio Guadarrama and Anoop Korattikara and Oscar Ramirez and
	     Pablo Castro and Ethan Holly and Sam Fishman and Ke Wang and
	     Ekaterina Gonina and Neal Wu and Efi Kokiopoulou and Luciano Sbaiz and
	     Jamie Smith and Gábor Bartók and Jesse Berent and Chris Harris and
	     Vincent Vanhoucke and Eugene Brevdo},
	  howpublished = {\url{https://github.com/tensorflow/agents}},
	  url = "https://github.com/tensorflow/agents",
	  year = 2018,
	  note = "[Online; accessed 25-June-2019]"
}

@article{huang2020closer,
	  title={A closer look at invalid action masking in policy gradient algorithms},
	  author={Huang, Shengyi and Onta{\~n}{\'o}n, Santiago},
	  journal={arXiv preprint arXiv:2006.14171},
	  year={2020}
}

@misc{cassirer2021reverb,
	      title={Reverb: A Framework For Experience Replay},
	      author={Albin Cassirer and Gabriel Barth-Maron and Eugene Brevdo and Sabela Ramos and Toby Boyd and Thibault Sottiaux and Manuel Kroiss},
	      year={2021},
	      eprint={2102.04736},
	      archivePrefix={arXiv},
	      primaryClass={cs.LG}
}

@article{silver2017mastering,
	  added-at = {2017-12-15T02:14:58.000+0100},
	  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	  biburl = {https://www.bibsonomy.org/bibtex/2ecdfbfcceb55ee5f14c1c375ad71f2cb/achakraborty},
	  description = {Mastering the game of Go without human knowledge | Nature},
	  interhash = {c45d318e105d0f2d62ccc28c2699d9d4},
	  intrahash = {ecdfbfcceb55ee5f14c1c375ad71f2cb},
	  journal = {Nature},
	  keywords = {2017 deep-learning deepmind google paper reinforcement-learning},
	  month = oct,
	  pages = {354--},
	  publisher = {Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	  timestamp = {2017-12-15T02:14:58.000+0100},
	  title = {Mastering the game of Go without human knowledge},
	  url = {http://dx.doi.org/10.1038/nature24270},
	  volume = 550,
	  year = 2017
}

@article{berner2019dota,
	  title={Dota 2 with large scale deep reinforcement learning},
	  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
	  journal={arXiv preprint arXiv:1912.06680},
	  year={2019}
}

@article{vinyals2019grandmaster,
	  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
	  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
	  journal={Nature},
	  volume={575},
	  number={7782},
	  pages={350--354},
	  year={2019},
	  publisher={Nature Publishing Group}
}


